{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McStas data to MJOLNIR data format, conversion script for BIFROST\n",
    "\n",
    "by: Kristine M. L. Krighaar\n",
    "\n",
    "created: 18/01/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KGS import * # Utilizing my own package for data analysis. Remember to also send enviroment when sharing. \n",
    "import scipp as sc\n",
    "import scippneutron as scn\n",
    "from scippneutron.conversion import graph\n",
    "import os\n",
    "from IPython.display import Image\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reduction process\n",
    "\n",
    "Full overview of how converison is done: \n",
    "\n",
    "![conversion_tree](DataReductionToMjolnir.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information from BIFROST_McStas_backend_information.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_info = pd.read_csv('../BIFROST_Design_Article/Energy_resolution/BIFROST_McStas_backend_information.csv')\n",
    "#back_info = back_info.loc[back_info['wedge_number'] == 1]\n",
    "\n",
    "back_info = np.asarray(back_info)[:,0:5]\n",
    "\n",
    "for j in range(len(back_info)):\n",
    "    back_info[j,3] = back_info[j,3].replace(',','.')\n",
    "    back_info[j,4] = back_info[j,3].replace(',','.')\n",
    "\n",
    "back_info = np.asarray(back_info, dtype=float)    \n",
    "    \n",
    "back_info = back_info[(back_info[:,0]== 2.7)  & (back_info[:,2]== 4) | (back_info[:,0]== 3.2) & (back_info[:,2]== 4)| (back_info[:,0]== 3.8) & (back_info[:,2]== 5) | (back_info[:,0]== 4.4) & (back_info[:,2]== 5) | (back_info[:,0]== 5.0) & (back_info[:,2]== 5)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Tube Measurment object\n",
    "\n",
    "This Object is designed to contain 1 tube mearsurment in a given A3, A4 setting. To this object the following information can be assosiated:\n",
    "\n",
    "**Should be defined from:** wedge, arc, tube\n",
    "\n",
    "Data:\n",
    "- I (y, t)\n",
    "- I _err (y,t)\n",
    "\n",
    "Axis:\n",
    "- t_s\n",
    "- y_m\n",
    "- A4\n",
    "\n",
    "Metadata:\n",
    "- A3 (sample rotation)\n",
    "- L_sd (length from detector to sample)\n",
    "- Ef (The Ef for the given analyser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class tube_measurement:\n",
    "    def __init__(self,wedge=0, arc=0, tube=0, I=0, I_err=0, t_s = 0, y_m = 0, A4=0, A3=0, L_sd=0, Ef=0):\n",
    "        self.wedge = wedge\n",
    "        self.arc = arc\n",
    "        self.tube = tube\n",
    "        self.I = I\n",
    "        self.I_err = I_err\n",
    "        self.t_s = t_s\n",
    "        self.y_m = y_m\n",
    "        self.A3 = A3\n",
    "        self.A4 = A4\n",
    "        \n",
    "        self.L_sd = L_sd\n",
    "        self.Ef = Ef\n",
    "    \n",
    "        \"\"\" Get L_sd \"\"\"\n",
    "        arc_values = {0: 2.7,1: 3.2,2: 3.8,3: 4.4,4: 5.0}\n",
    "\n",
    "        # Loop through each arc value\n",
    "        for arc, value in arc_values.items():\n",
    "            # Check if the current arc value matches self.arc\n",
    "            if self.arc == arc:\n",
    "                # Filter the corresponding row from back_info\n",
    "                ar = back_info[back_info[:, 0] == value]\n",
    "                \n",
    "                # Determine wedge conditions and calculate self.L_sd accordingly\n",
    "                if self.wedge in (0, 3, 6):\n",
    "                    self.L_sd = ar[0, 3] + ar[0, 4]\n",
    "                elif self.wedge in (1, 4, 7):\n",
    "                    self.L_sd = ar[1, 3] + ar[1, 4]\n",
    "                elif self.wedge in (2, 5, 8):\n",
    "                    self.L_sd = ar[2, 3] + ar[2, 4]\n",
    "                break  # Exit the loop after finding the matching arc value\n",
    "\n",
    "\n",
    "    def getI(self, filename):\n",
    "        \"\"\"\n",
    "        Loading the data from the \n",
    "        \"\"\"\n",
    "        with h5py.File(filename, 'r') as file:\n",
    "            self.I = file['entry1/data/signal_1Dspace_'+str(self.wedge)+'_'+str(self.arc)+'_'+str(self.tube)+'_dat/data'][()].astype('int64')\n",
    "        return self.I\n",
    "    \n",
    "    def getI_err(self, filename):\n",
    "        with h5py.File(filename, 'r') as file:\n",
    "            self.I_err = file['entry1/data/signal_1Dspace_'+str(self.wedge)+'_'+str(self.arc)+'_'+str(self.tube)+'_dat/errors'][()].astype('int64')\n",
    "        return self.I_err\n",
    "    \n",
    "    def get_t_s(self, filename):\n",
    "        with h5py.File(filename, 'r') as file:\n",
    "            self.t_s = file['entry1/data/signal_1Dspace_'+str(self.wedge)+'_'+str(self.arc)+'_'+str(self.tube)+'_dat/t__s_'][()]\n",
    "        return self.t_s\n",
    "    \n",
    "    def get_y_m(self, filename):\n",
    "        with h5py.File(filename, 'r') as file:\n",
    "            self.y_m = file['entry1/data/signal_1Dspace_'+str(self.wedge)+'_'+str(self.arc)+'_'+str(self.tube)+'_dat/y__m_'][()]\n",
    "        return self.y_m\n",
    "    \n",
    "    def getA3(self, filename): # Husk at finde rigtig index til A3\n",
    "        with h5py.File(filename, 'r') as file:\n",
    "            A3 = file['entry1/simulation/Param/A3'][()].astype('int64')[0]\n",
    "            self.A3 = A3\n",
    "        return self.A3\n",
    "    \n",
    "    \n",
    "    def getA4(self, filename):\n",
    "        #if self.y_m == 0:\n",
    "        #    print('ERROR: Before A4 can be calculated first y_m need to be assigned by the .get_y_m(filename) function! ')\n",
    "        \n",
    "        # Get the angular offset from direct beam to first wedge\n",
    "        with h5py.File(filename, 'r') as file:\n",
    "            A4_offset = file['entry1/simulation/Param/A4'][()].astype('int64')[0]\n",
    "            A4_offset = A4_offset\n",
    "\n",
    "        # Get the angular offset from wedge number\n",
    "        wedge_offsets = np.array([0, 10, 20, 30, 40, 50, 60, 70, 80])\n",
    "        wedge_offset = wedge_offsets[self.wedge]\n",
    "            \n",
    "        # Calculate the A4 degrees for each pixel on tube\n",
    "        dA4 = np.degrees(np.arctan((self.y_m/self.L_sd)))\n",
    "        \n",
    "        # Add the offset for tank and wedge number\n",
    "        self.A4 = A4_offset + wedge_offset + dA4\n",
    "\n",
    "        return self.A4 \n",
    "    \n",
    "    \"\"\" Get Ef (Think about making the Ef correction based on the dA4 takeoff angle) \"\"\"\n",
    "    if arc == 0:\n",
    "        self.Ef = 2.7\n",
    "    if arc == 1:\n",
    "        self.Ef = 3.2\n",
    "    if arc == 2:\n",
    "        self.Ef = 3.8\n",
    "    if arc == 3:\n",
    "        self.Ef = 4.4\n",
    "    if arc == 4:\n",
    "        self.Ef = 5.0\n",
    "\n",
    "\n",
    "scan_file_path = '../McStasScript/run_folder/test3/mccode.hdf5'\n",
    "\n",
    "ob = tube_measurement(wedge=8, arc=4, tube=2)\n",
    "ob.getI(scan_file_path)\n",
    "ob.getI_err(scan_file_path)\n",
    "\n",
    "ob.get_t_s(scan_file_path)\n",
    "ob.get_y_m(scan_file_path)\n",
    "ob.getA4(scan_file_path)\n",
    "\n",
    "ob.getA3(scan_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing datastructure in scipp \n",
    "\n",
    "Datastructure includes lab information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipp_dict = {}\n",
    "for i in range(2):\n",
    "    key = f'A3 setting{i}'\n",
    "    value = sc.array(dims=['tube', 'y', 't'], values=data[0], variances=data[1])\n",
    "    scipp_dict[key] = value\n",
    "\n",
    "print(scipp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = sc.Dataset(\n",
    "    data=scipp_dict, # sc.array(dims=['y', 't', 'tube'], values=I_A3),\n",
    "    coords={\n",
    "        'y': sc.array(dims=['y'], values=data[2], unit='m'),\n",
    "        't': sc.array(dims=['t'], values=data[3], unit='s'),\n",
    "        'L_sd': sc.array(dims=['tube'], values=np.arange(27.0)),\n",
    "        'Ana': sc.array(dims=['tube'], values=np.ones(27)*5),\n",
    "        'wedge': sc.array(dims=['tube'], values=np.arange(27.0)),\n",
    "    },\n",
    ")\n",
    "\n",
    "sc.show(sim_data)\n",
    "sim_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the data reduction tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backscattered_l2(position, sample_position, analyzer_position):\n",
    "    \"\"\"\n",
    "    Compute the length of the secondary flight path for backscattering off an analyzer.\n",
    "    \"\"\"\n",
    "    return sc.norm(position - analyzer_position) + sc.norm(\n",
    "        analyzer_position - sample_position\n",
    "    )\n",
    "\n",
    "\n",
    "def wavelength_from_analyzer(analyzer_dspacing, analyzer_angle):\n",
    "    \"\"\"\n",
    "    Compute the neutron wavelength after scattering from the analyzer's d-spacing.\n",
    "\n",
    "    Assuming Bragg scattering in the analyzer, the wavelength is\n",
    "        wavelength = 2 * d * sin(theta)\n",
    "\n",
    "    Where\n",
    "        d is the analyzer's d-spacing,\n",
    "        theta is the scattering angle or equivalently, the tilt of the analyzer\n",
    "              w.r.t. to the sample-analyzer axis.\n",
    "    \"\"\"\n",
    "    # 2*theta is the angle between transmitted and scattered beam.\n",
    "    return (\n",
    "        2\n",
    "        * analyzer_dspacing\n",
    "        * sc.sin(sc.scalar(np.pi / 2, unit=\"rad\") - analyzer_angle.to(unit=\"rad\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scippneutron.conversion.graph.beamline import beamline\n",
    "from scippneutron.conversion.tof import energy_transfer_indirect_from_tof\n",
    "\n",
    "graph = {\n",
    "    **beamline(scatter=True),\n",
    "    \"energy_transfer\": energy_transfer_indirect_from_tof,\n",
    "    # Replace L2 with our own implementation.\n",
    "    \"L2\": backscattered_l2,\n",
    "    # Insert a new function for the wavelength.\n",
    "    \"final_wavelength\": wavelength_from_analyzer,\n",
    "}\n",
    "# Optional: remove unused functions in order to clean up the image below.\n",
    "del graph[\"two_theta\"]\n",
    "del graph[\"scattered_beam\"]\n",
    "del graph[\"Ltotal\"]\n",
    "#sc.show_graph(graph, simplified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
